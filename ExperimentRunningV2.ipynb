{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of the different experiment setups\n",
    "The designs of the experiments are explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## featureClf\n",
    "input:  \n",
    "@did: openML dataset id the experiments is run over   \n",
    "@cv: the number of folds in the cross-validation  \n",
    "@amount: the number of features added or removed  \n",
    "@type: the sort of feature manipulation  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; typ == 0 or typ == 5: in each fold, the value for @amount is used to remove a number of features from the dataset. The features are chosen randomly and might be different between the training and test set in the cross-validation.   \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; typ == 1: in each fold, the value for @amount is used to add a number of features to the dataset. These features are uniform random values between 0 and 1.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; typ == 2: in each fold, the value for @amount is used to add a number of features to the dataset. These features are random features based on the types of features in the original dataset. For a categorical random feature the default method is taking a uniform random value between 0 and 100 and then rounding down to the nearest integer. The numerical random value is uniform random value between 0 and 1.   \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; typ == 3: in each fold, the value for @amount is used to add a number of features to the dataset. The features added to the cross-validation training set are randomly chosen duplicates and the features added to the cross-validation test set are also randomly chosen duplicates.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; typ == 4: in each fold, the value for @amount is used to add a number of features to the dataset. The first @amount features in the dataset are also added to the dataset.\n",
    "&nbsp; &nbsp;&nbsp; &nbsp; typ == 5: in each fold, the value for @amount is used to remove a number of features from the dataset. The features are chosen randomly and might be different between the training and test set in the cross-validation.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; typ == 6: in each fold, the value for @amount is used to replace the dataset with a number of random features. These uniform random features can be either natural numbers between 0 and 100, real numbers between 0 and 1 or both depending on the type of features in the original dataset.    \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; typ == 7: in each fold, the value for @amount is used to replace the dataset with a number of random features. These random features are gaussian distributed with categorical values with the random variable being 50 and the variance also being 50. The numerical values have the random variable being 0 and the variance being 1.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; typ == 8: in each fold, the value for @amount is used to add a number of features to the dataset. These features are random features based on the opposite types of features in the original dataset. For a categorical random feature the default method is taking a uniform random value between 0 and 100 and then rounding down to the nearest integer. The numerical random value is uniform random value between 0 and 1. The  \n",
    "\n",
    "@output a directory with 5 different kind of files for each classifier included   \n",
    "&nbsp; &nbsp; &nbsp; &nbsp;-scores: 2 rows and for each fold in the cross-validation a collumn of the score. The first row is the result of a cross-validation without manipulation and the second row is with manipulation.   \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; -SummaryGuesses: 2 rows and for each fold in the cross-validation a collumn of all predictions summed up. Again the first for no manipulation and the second with manipulation. The entries are stored as dictionaries to indicate which class is predicted.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; -Predictions: 3 files are made, the first for the dataset without, the second with manipulation and the third the ground truth. The content of the files are a row for each fold in the cross-validation. The rows consists of the prediction/truth per instance.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; -duration: the first value is the total time needed for classifying the datasets without manipulation needed for the cross-validation. The second value is the total time needed to predict in the cross-validation for the dataset without manipulation. The third and fourth are the same sort time values but for the dataset with manipulation.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import featureClf\n",
    "cv = 10 \n",
    "amountList = []\n",
    "didList = []\n",
    "typs = [2,3,4]\n",
    "for did in didList:\n",
    "    for amount in amountList:\n",
    "        for typ in typs:\n",
    "            featureClf(did,cv,round(amount*(readDict(did)['NumberOfFeatures']-1)),typ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## featureClfPre\n",
    "The difference between this and featureClf is an added step of preprocessing of the datasets in the cross validation in each fold.\n",
    "input:  \n",
    "@did: openML dataset id the experiments is run over   \n",
    "@cv: the number of folds in the cross-validation  \n",
    "@amount: the number of features added or removed  \n",
    "@type: the sort of feature manipulation  \n",
    "output: The same as featureClf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import featureClfPre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv_scores_noise\n",
    "\n",
    "@did: openML dataset id the experiments is run over.   \n",
    "@cv: the number of folds in the cross-validation.  \n",
    "@amount: the number of features added or removed.  \n",
    "@type: the sort of noise the features are affected by.  \n",
    "output: a directory with 3 different kind of files for each classifier included  \n",
    "&nbsp; &nbsp; &nbsp; &nbsp;-scores: 4 rows and for each fold in the cross-validation a collumn of the score. The first row is the score of the classifier trained and predicted on the original dataset and the second row is the same classifier with the noisy data as test. The third row is the score of the classifier trained with noisy data on the noisy data. The last row is the score of this classifier on the original dataset.  \n",
    "&nbsp; &nbsp; &nbsp; &nbsp;- predictions: are the predicted classes for the scores for each experiment type a file and an extra file for the true value of the classes.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; SummaryGuesses: 4 rows and for each fold in the cross-validation a collumn of all predictions summed up. The same order as the scores and predictions. The entries are stored as dictionaries to indicate which class is predicted.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import cv_scores_noise\n",
    "cv_scores_noise(did,cv,amount,cvScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv_feature\n",
    "This experiment adds noise to datasets depending on the type defined in OpenML. For numerical features, the standard deviation (std) is calculated and the @amount is used as a ratio. For all the instances in the test set the standard deviation times @amount times a uniform random number between 0 and 1 times the original value. In a cross-validation, the accuracy and more is calculated to define how good a classifier predicted compared to each other. For categorical features, all the instances are counted and the average occurrence is used. A random value is chosen between 0 and 1, multiplied by @amount and if the value is higher than 0.5 a feature instance is replaced by a random category balanced on the occurences.    \n",
    "@did OpenML dataset id.  \n",
    "@cv the amount of folds in a cross-validation.  \n",
    "@amount the range of noise that the instances might be.  \n",
    "output: a directory with 4 different kind of files for each classifier.  \n",
    "&nbsp; &nbsp; &nbsp; &nbsp;-scores: 2 rows and for each fold in the cross-validation a collumn of the score. The first row is the score of the classifier trained and predicted on the original dataset and the second row is the same classifier with the noisy data as test set   \n",
    "&nbsp; &nbsp; &nbsp; &nbsp;- predictions: are the predicted classes for the scores for each experiment type a file and an extra file for the true value of the classes.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; -SummaryGuesses: 2 rows and for each fold in the cross-validation a collumn of all predictions summed up. The same order as the scores and predictions. The entries are stored as dictionaries to indicate which class is predicted.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; -Duration: 3 values of duration for the execution of the cross-validation. The first value is the fitting of a classifier to the datasets. The second value is the prediction on the original dataset and the third on the dataset with noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compeleteRun import cv_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv_featurePre\n",
    "The same as cv_feature but with preprocessing for the classifiers: kNN, SGDClassifier and SVC-rbf. The preprocessing steps are a OneHotEncoder for categorical features and after that a StandardScaler on the whole dataset.   \n",
    "output: another type of file that is created is order. This file stores the order of the dataset after shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compeleteRun import cv_featurePre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizeCVclfs\n",
    "This experiment is a repeat of cv_feature but with an attempt at optimizing the classifiers. THis also means that a subset of classifiers is displayed. The classifiers: SVC-rbf, GradientBoostingClassifier, RandomForestClassifier, AdaBoost and kNN are optimized on some of their parameters. This is done on the training set with the RandomizedSearchCV function from the scikit-learn library.\n",
    "input:  \n",
    "@did OpenML dataset id   \n",
    "@amount the range of noise that the instances might be. \n",
    "@cv the amount of folds in a cross-validation.  \n",
    "output: \n",
    "output: a directory with 4 different kind of files for each classifier.  \n",
    "&nbsp; &nbsp; &nbsp; &nbsp;-scores: 2 rows and for each fold in the cross-validation a collumn of the score. The first row is the score of the classifier trained and predicted on the original dataset and the second row is the same classifier with the noisy data as test set   \n",
    "&nbsp; &nbsp; &nbsp; &nbsp;- predictions: are the predicted classes for the scores for each experiment type a file and an extra file for the true value of the classes.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; -Estimators: the configurations that appeared to give the most predicive accuracy.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; -Duration: 3 values of duration for the execution of the cross-validation. The first value is the fitting of a classifier to the datasets. The second value is the prediction on the original dataset and the third on the dataset with noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import optimizeCVclfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## featureOptClf, featureOptClf2 and featureOptClf3\n",
    "The same experiment as featureClf is executed but with the classifiers that are being optimized, the same method as in optimizeCVclfs. Added files are:  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp;order: This file stores the order of the dataset after shuffling.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp;Estimators: the configurations that appeared to give the most predicive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import featureOptClf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoiseOptClf2\n",
    "The same experiment as cv_feature but with the classifiers being optimized. This is also complemented with two new outputs:  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; -Estimators: the configurations that appeared to give the most predicive accuracy.  \n",
    "&nbsp; &nbsp;&nbsp; &nbsp; -Order: This file stores the order of the dataset after shuffling  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import NoiseOptClf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizeIdenCVclf\n",
    "The same experiment as optimizeCVclfs but with an extra input.  \n",
    "@iden: the order of instances in the dataset, to match an already executed experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import optimizeIdenCVclf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## featureRemovedClf\n",
    "The same experiment as featureClf with typ == 0 or typ == 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import featureRemovedClf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## featureYClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import featureYClf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute_bias_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import compute_bias_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute_bias_variancePart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import compute_bias_variancePart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv_featurePre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import cv_featurePre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## featureClfAdj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import featureClfAdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## featureRemoving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from completeRun import featureRemoving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
